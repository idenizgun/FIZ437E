{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from time import process_time\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root ='./data',train = True,transform = transforms.ToTensor(),download = True)\n",
    "test_dataset = dsets.MNIST(root ='./data',train = False,transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bilgisayarım 3 kere çöktüğünden dolayı datayı azaltma yoluna gitmek zorunda kaldım\n",
    "a = 20000\n",
    "#red_train = color(train_dataset.data[:],\"red\")\n",
    "#green_train = color(train_dataset.data[:],\"green\")\n",
    "#blue_train = color(train_dataset.data[:],\"blue\")\n",
    "#yellow_train = color(train_dataset.data[:],\"yellow\")\n",
    "#white_train = color(train_dataset.data[:],\"white\")\n",
    "#torch.save(red_train,\"red_train.pt\")\n",
    "#torch.save(green_train,\"green_train.pt\")\n",
    "#torch.save(blue_train,\"blue_train.pt\")\n",
    "#torch.save(yellow_train,\"yellow_train.pt\")\n",
    "#torch.save(white_train,\"white_train.pt\")\n",
    "red_train = torch.load(\"red_train.pt\")\n",
    "green_train = torch.load(\"green_train.pt\")\n",
    "blue_train = torch.load(\"blue_train.pt\")\n",
    "yellow_train = torch.load(\"yellow_train.pt\")\n",
    "white_train = torch.load(\"white_train.pt\")\n",
    "l = train_dataset.targets[:a]\n",
    "labels_train = torch.cat((l,l,l,l,l),0)\n",
    "\n",
    "train_dataset = TensorDataset(torch.cat((red_train[:a],green_train[:a],blue_train[:a],yellow_train[:a],white_train[:a]),0),labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10000\n",
    "#red_test = color(test_dataset.data[:],\"red\")\n",
    "#green_test = color(test_dataset.data[:],\"green\")\n",
    "#blue_test = color(test_dataset.data[:],\"blue\")\n",
    "#yellow_test = color(test_dataset.data[:],\"yellow\")\n",
    "#white_test = color(test_dataset.data[:],\"white\")\n",
    "#torch.save(red_test,\"red_test.pt\")\n",
    "#torch.save(green_test,\"green_test.pt\")\n",
    "#torch.save(blue_test,\"blue_test.pt\")\n",
    "#torch.save(yellow_test,\"yellow_test.pt\")\n",
    "#torch.save(white_test,\"white_test.pt\")\n",
    "red_test = torch.load(\"red_test.pt\")\n",
    "green_test = torch.load(\"green_test.pt\")\n",
    "blue_test = torch.load(\"blue_test.pt\")\n",
    "yellow_test = torch.load(\"yellow_test.pt\")\n",
    "white_test = torch.load(\"white_test.pt\")\n",
    "l = test_dataset.targets[:a]\n",
    "labels_test = torch.cat((l,l,l,l,l),0)\n",
    "\n",
    "test_dataset = TensorDataset(torch.cat((red_test[:a],green_test[:a],blue_test[:a],yellow_test[:a],white_test[:a]),0),labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_dataset.tensors[0].numpy().astype(np.float32).reshape([-1, 28*28*3])\n",
    "train_labels = train_dataset.tensors[1].numpy().astype(np.float32)\n",
    "test_data = test_dataset.tensors[0].numpy().astype(np.float32).reshape([-1, 28*28*3])\n",
    "test_labels = test_dataset.tensors[1].numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omer-\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score:  0.89906\n"
     ]
    }
   ],
   "source": [
    "svm_with_reg = LinearSVC(random_state=True,penalty=\"l2\", loss=\"squared_hinge\", dual=True)\n",
    "svm_with_reg.fit(train_data,train_labels)\n",
    "pred = svm_with_reg.predict(test_data)\n",
    "\n",
    "print(\"The accuracy score: \", accuracy_score(test_labels,pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW2_SVM_with_Regularization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
